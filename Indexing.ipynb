{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2784796f",
   "metadata": {},
   "source": [
    "### Setting up elastic search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e566274",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'aba709d5764b',\n",
       " 'cluster_name': 'docker-cluster',\n",
       " 'cluster_uuid': 'aq-DUWdOT0mjoUCmqP0GZQ',\n",
       " 'version': {'number': '8.7.0',\n",
       "  'build_flavor': 'default',\n",
       "  'build_type': 'docker',\n",
       "  'build_hash': '09520b59b6bc1057340b55750186466ea715e30e',\n",
       "  'build_date': '2023-03-27T16:31:09.816451435Z',\n",
       "  'build_snapshot': False,\n",
       "  'lucene_version': '9.5.0',\n",
       "  'minimum_wire_compatibility_version': '7.17.0',\n",
       "  'minimum_index_compatibility_version': '7.0.0'},\n",
       " 'tagline': 'You Know, for Search'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "es = Elasticsearch(\"http://localhost:9200\")\n",
    "es.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c53ddb8",
   "metadata": {},
   "source": [
    "### Creating an index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1510115a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acknowledged': True,\n",
       " 'shards_acknowledged': True,\n",
       " 'index': 'passage_embeddings_idx'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing Data Into Elastic Search.\n",
    "\n",
    "index_name = \"passage_embeddings_idx\"\n",
    "index_mapping = {\n",
    "    \"mappings\":{\n",
    "        \"dynamic\":\"true\",\n",
    "        \"properties\":{\n",
    "            \"passages\": {\n",
    "                \"type\": \"text\"\n",
    "            },\n",
    "            \"metadata\":{\n",
    "                \"type\":\"object\"\n",
    "            },\n",
    "            \"embedding\":{\n",
    "                \"type\":\"dense_vector\",\n",
    "                \"dims\": 768\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "if es.indices.exists(index=index_name): es.indices.delete(index=index_name)\n",
    "\n",
    "es.indices.create(index = index_name, body = index_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f9fa71",
   "metadata": {},
   "source": [
    "### Creating documents for passage_metadata index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce56405",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the fixed CSV file\n",
    "import csv\n",
    "import json\n",
    "\n",
    "fixed_csv_file = \"./docs/passage_metadata_emb.csv\"\n",
    "\n",
    "# Open the fixed CSV file\n",
    "with open(fixed_csv_file, \"r\", encoding = \"utf-8\") as file:\n",
    "    csv_reader = csv.reader(file)\n",
    "    # Skip the header row if it contains column names\n",
    "    next(csv_reader, None)\n",
    "    \n",
    "    for row in csv_reader:\n",
    "        Passage, Metadata, Embeddings = row  # Assuming these are the column names in your CSV\n",
    "        \n",
    "        metadata_dict = json.loads(Metadata)\n",
    "        embeddings = json.loads(Embeddings)\n",
    "        \n",
    "        # Define the document to be indexed\n",
    "        document = {\n",
    "            \"passage\": Passage,\n",
    "            \"metadata\": metadata_dict,\n",
    "            \"embedding\": embeddings\n",
    "        }\n",
    "        \n",
    "        # Index the document into Elasticsearch\n",
    "        es.index(index=index_name, document=document)\n",
    "\n",
    "# Refresh the index to make the data available for searching\n",
    "es.indices.refresh(index=index_name)\n",
    "\n",
    "# Check the document count in the index\n",
    "es.cat.count(index=index_name, format=\"json\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3850d545",
   "metadata": {},
   "source": [
    "### Endcoder for embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1935271",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model_name = \"all-mpnet-base-v2\"\n",
    "model = SentenceTransformer(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae13385",
   "metadata": {},
   "source": [
    "### Retrieval of passages when queried"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803a2a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd\n",
    "# Retrieve relevant passages\n",
    "def retrieve_passages(index_name,question, top_k = 3, model = model):\n",
    "    query = {\n",
    "        \"query\": {\n",
    "            \"match\": {\n",
    "                \"passage\": question\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    results = es.search(index = index_name, body = query, size = top_k)\n",
    "\n",
    "    question_embedding = model.encode(question)\n",
    "\n",
    "    passages = []\n",
    "    relevance_scores = []\n",
    "    passage_metadata = []\n",
    "    for hit in result[\"hits\"][\"hits\"]:\n",
    "        passages.append(hit[\"_source\"][\"passage\"])\n",
    "        relevance_scores.append(cosine_similarity([question_embedding], [hit[\"_source\"][\"embedding\"]])[0][0])\n",
    "        passage_metadata.append(hit[\"_source\"][\"metadata\"])\n",
    "\n",
    "    return passages, relevance_scores, passage_metadata\n",
    "\n",
    "question = \"What is a valid offer?\"\n",
    "passages, relevance_scores, meta_data = retrieve_passages(index_name = index_name, question=question)\n",
    "results_df = pd.DataFrame({\n",
    "    \"Question\" : [question] * len(passages),\n",
    "    \"Passage\" : passages,\n",
    "    \"Relevance Scores\": relevance_scores,\n",
    "    \"Passage Metadata\": meta_data\n",
    "})\n",
    "results_df.to_csv(\"./docs/question_answering.csv\", index = False)\n",
    "results_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
